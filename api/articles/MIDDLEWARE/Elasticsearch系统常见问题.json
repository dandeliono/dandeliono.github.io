{"title":"Elasticsearch系统常见问题","uid":"f086d547e55f7aeb852f476ef6c33b8e","slug":"MIDDLEWARE/Elasticsearch系统常见问题","date":"2021-11-17T10:00:10.000Z","updated":"2025-12-05T01:47:25.787Z","comments":true,"path":"api/articles/MIDDLEWARE/Elasticsearch系统常见问题.json","keywords":"XuGuangSheng","cover":"/covers/elasticsearch.jpg","content":"<h1 id=\"Elasticsearch系统常见问题\"><a href=\"#Elasticsearch系统常见问题\" class=\"headerlink\" title=\"Elasticsearch系统常见问题\"></a>Elasticsearch系统常见问题</h1><h2 id=\"如何查看-Es-安装了哪些插件\"><a href=\"#如何查看-Es-安装了哪些插件\" class=\"headerlink\" title=\"如何查看 Es 安装了哪些插件\"></a><a href=\"#%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8Bes%E5%AE%89%E8%A3%85%E4%BA%86%E5%93%AA%E4%BA%9B%E6%8F%92%E4%BB%B6\"></a>如何查看 Es 安装了哪些插件</h2><p>可以使用下面这个 API，会列出每个节点安装的插件列表。</p>\n<h2 id=\"线程池队列满导致错误\"><a href=\"#线程池队列满导致错误\" class=\"headerlink\" title=\"线程池队列满导致错误\"></a><a href=\"#%E7%BA%BF%E7%A8%8B%E6%B1%A0%E9%98%9F%E5%88%97%E6%BB%A1%E5%AF%BC%E8%87%B4%E9%94%99%E8%AF%AF\"></a>线程池队列满导致错误</h2><p>在这种场景下 ES 抛出的异常是</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><pre><code>rejected execution of org.elasticsearch.transport.TransportService$4@c8998f4 \non EsThreadPoolExecutor[bulk, queue capacity = 50, org.elasticsearch.common.util.concurrent.EsThreadPoolExecutor@553aee29\n[Running, pool size = 4, active threads = 4, queued tasks = 50, completed tasks = 0]]\n</code></pre></blockquote>\n<p>ES 内部有很多线程池，比如 index，search，bulk 是我们能够看到的 3 个典型的线程池，如果系统的压力特别大，后台线程处理不过来的时候，用户发起的任务会在线程池的队列里堆积，如果达到队列的上限就会抛出对应的异常，遇到这种错误需要做以下两步：</p>\n<ul>\n<li><p>检查系统的 CPU 和 IO 的利用情况，如果系统的 IO 和 CPU 的利用率比较高，这说明系统遇到资源瓶颈了，已经不能通过优化系统的参数来避免这种错误发生了，云上的用户可以在 ES 的控制台查看 ES 的 CPU 利用率，也可以通过 ES 自带的命令来查看，通过下面这个命令可以看到 ES 各个节点的 CPU 利用率以及负载： GET &#x2F;_cat&#x2F;nodes?v</p>\n</li>\n<li><p>如果资源没有问题，那么检查当先线程池的配置，比如上面这个错误就需要检查 bulk 的线程池的配置，在 sense 里执行以下命令： GET &#x2F;_cluster&#x2F;settings</p>\n<p>结果如下</p>\n<pre><code> &quot;thread_pool&quot;: &#123;\n       &quot;bulk&quot;: &#123;\n          &quot;type&quot;: &quot;fixed&quot;,\n          &quot;size&quot;: &quot;4&quot;,\n          &quot;queue_size&quot;: &quot;50&quot;\n       &#125;\n    &#125;\n</code></pre>\n<p>这个结果表示处理 bulk 任务的线程池有 4 个执行线程，队列数为 50. 根据我们的经验看，这个值还是比较小的，所以可以直接用以下操作处理：</p>\n</li>\n</ul>\n<p>ES 5.5.0 版本：</p>\n<pre><code>PUT /_cluster/settings\n&#123;\n    &quot;persistent&quot;: &#123;\n        &quot;thread_pool.bulk.size&quot;: 32,\n        &quot;thread_pool.bulk.queue_size&quot;: 300\n    &#125;\n&#125;\n</code></pre>\n<p>ES 6.5.3+ 集群：</p>\n<pre><code>PUT /_cluster/settings\n&#123;\n    &quot;persistent&quot;: &#123;\n        &quot;thread_pool.write.size&quot;: 32,\n        &quot;thread_pool.write.queue_size&quot;: 300\n    &#125;\n&#125;\n</code></pre>\n<h2 id=\"Too-Many-Open-Files-的错误\"><a href=\"#Too-Many-Open-Files-的错误\" class=\"headerlink\" title=\"Too Many Open Files 的错误\"></a><a href=\"#too-many-open-files%E7%9A%84%E9%94%99%E8%AF%AF\"></a>Too Many Open Files 的错误</h2><p>在 es 的日志中如果出现这个错误，一般都是打开的文件太多了，ES 建议文件句柄的限制至少为 65536 个，用户可以通过修改 &#x2F;etc&#x2F;security&#x2F;limits.conf 来修改，或者用 ulimit 这个命令来修改。 es 里每个 shard 都是一个单独的 lucene index writer，每个 shard 由多个 segment 组成，每个 segment 有多个文件，所以打开的文件的数目 &#x3D; shard 数目 <em>segment 数目</em> 每个 segment 包含的文件数量，所以我们建议一个物理机节点上 shard 的数目在 1000 个左右，不建议有太多的 shard。另外 lucene 使用 compound file 格式也能有效的减少每个 segment 里的文件的数量。</p>\n<h2 id=\"Es-中一个分片一般设置多大\"><a href=\"#Es-中一个分片一般设置多大\" class=\"headerlink\" title=\"Es 中一个分片一般设置多大\"></a><a href=\"#es-%E4%B8%AD%E4%B8%80%E4%B8%AA%E5%88%86%E7%89%87%E4%B8%80%E8%88%AC%E8%AE%BE%E7%BD%AE%E5%A4%9A%E5%A4%A7\"></a>Es 中一个分片一般设置多大</h2><p>ES 的每个分片（shard）都是 lucene 的一个 index，而 lucene 的一个 index 只能存储 20 亿个文档，所以一个分片也只能最多存储 20 亿个文档。 另外，我们也建议一个分片的大小在 10G-50G 之间，太大的话查询时会比较慢，另外在做副本修复的时，耗时比较多；分片太小的话，会导致一个索引的分片数目很多，查询时带来的 fanout 太大。</p>\n<h2 id=\"当集群为-red-或者-yellow-的时候怎么办\"><a href=\"#当集群为-red-或者-yellow-的时候怎么办\" class=\"headerlink\" title=\"当集群为 red 或者 yellow 的时候怎么办\"></a><a href=\"#%E5%BD%93%E9%9B%86%E7%BE%A4%E4%B8%BAred%E6%88%96%E8%80%85yellow%E7%9A%84%E6%97%B6%E5%80%99%E6%80%8E%E4%B9%88%E5%8A%9E\"></a>当集群为 red 或者 yellow 的时候怎么办</h2><p>集群为 RED 表示集群中有 primary shard 没有分配，yellow 表示有 replica 没有分配，我们建议你用下面这个 API 来看 shard 为什么没有被分配到某个节点上。 GET _cluster&#x2F;allocation&#x2F;explain</p>\n<p>根据我们的使用经验，有以下几种情况导致 shard 没有被分配：</p>\n<ul>\n<li>没有节点上有存储空间能够放下这个 shard。</li>\n<li>如果 shard 是 replica，那么可能是 primary shard 未分配或者处于 initializing 状态。</li>\n</ul>\n<p><strong>分片长时间处于未分配状态</strong> ES 内部会对一个 unassigned 分片尝试 5 次进行分配, 失败后不再尝试进行分配，这时候需要调用进行手动控制集群处理 unassigned 分片：</p>\n<pre><code>POST /_cluster/reroute?retry_failed=true\n</code></pre>\n<h2 id=\"如何-cancel-掉慢查询\"><a href=\"#如何-cancel-掉慢查询\" class=\"headerlink\" title=\"如何 cancel 掉慢查询\"></a><a href=\"#%E5%A6%82%E4%BD%95cancel%E6%8E%89%E6%85%A2%E6%9F%A5%E8%AF%A2\"></a>如何 cancel 掉慢查询</h2><p>用户发送一个查询可能导致一个集群非常慢，CPU 利用率非常高，所以用户有的时候想把占用资源非常多的查询 cancel 掉。在 ES 5.0 之后 es 提供了 cancel 查询的命令。 es 内部把所有的执行任务都封装成了 task，可以通过 task api 来查看一个节点在执行的 task 任务列表，也可以使用 task api 来取消 task。比如我们要查询所有在执行 search 类型的 task，可以使用如下 API： GET &#x2F;_tasks?actions&#x3D;*search</p>\n<p>取消所有在执行的 search 任务：</p>\n<pre><code>POST _tasks/_cancel?actions=*search\n</code></pre>\n<p>更多的使用方式可以参考<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/tasks.html\">官方网站</a>的介绍。</p>\n<h2 id=\"PageCache-在查询中的作用很大\"><a href=\"#PageCache-在查询中的作用很大\" class=\"headerlink\" title=\"PageCache 在查询中的作用很大\"></a><a href=\"#pagecache-%E5%9C%A8%E6%9F%A5%E8%AF%A2%E4%B8%AD%E7%9A%84%E4%BD%9C%E7%94%A8%E5%BE%88%E5%A4%A7\"></a>PageCache 在查询中的作用很大</h2><p>我们建议如果条件可以的话应该给 ES 留尽量多的 pagecache，这能极大的优化我们的查询速度，如果 pagecache 不足够多，那么 ES 每次查询【fetch 文档，拿 posting list】都会读取磁盘，此时系统就会变慢。 用户可以使用 iostat 来查看一下系统的 IO 信息，也可在 GET _nodes&#x2F;state 返回的信息里搜索 “io_stats” 查看。如果 iops 比较高的话，说明系统的 io 比较高了，可能就是 pagecache 小的原因。</p>\n<h2 id=\"禁用权限验证\"><a href=\"#禁用权限验证\" class=\"headerlink\" title=\"禁用权限验证\"></a><a href=\"#%E7%A6%81%E7%94%A8%E6%9D%83%E9%99%90%E9%AA%8C%E8%AF%81\"></a>禁用权限验证</h2><p>有的时候业务系统原有的 ES 服务没有权限验证，但是云上的 ES 服务是有权限验证的，当业务系统迁移的时候不希望改代码，那么可以先把权限验证关掉，这样就能平滑迁移了。操作的方式是：</p>\n<pre><code>PUT /_cluster/settings\n&#123;\n    &quot;persistent&quot;: &#123;\n        &quot;simpleauth.enable&quot;:false\n    &#125;\n&#125;\n</code></pre>\n<h2 id=\"支持的-Client-的类型\"><a href=\"#支持的-Client-的类型\" class=\"headerlink\" title=\"支持的 Client 的类型\"></a><a href=\"#%E6%94%AF%E6%8C%81%E7%9A%84client%E7%9A%84%E7%B1%BB%E5%9E%8B\"></a>支持的 Client 的类型</h2><p>目前我们云上的产品只支持基于 http 的 restful api，不支持基于 tcp 的 transport client 这种 api。 这个设置主要原因是 transport client 跟集群运行的版本深度绑定，当集群升级的时候需要前端业务也跟着升级才可以。</p>\n<h2 id=\"Es-是否支持-Spark-和-Hadoop-来写入或者读取数据\"><a href=\"#Es-是否支持-Spark-和-Hadoop-来写入或者读取数据\" class=\"headerlink\" title=\"Es 是否支持 Spark 和 Hadoop 来写入或者读取数据\"></a><a href=\"#es%E6%98%AF%E5%90%A6%E6%94%AF%E6%8C%81spark%E5%92%8Chadoop%E6%9D%A5%E5%86%99%E5%85%A5%E6%88%96%E8%80%85%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE\"></a>Es 是否支持 Spark 和 Hadoop 来写入或者读取数据</h2><p>支持，需要到 es 官方网站下载 es-hadoop 包放到 spark 或者 hadoop 中就可以用 spark 或者 hadoop 读写 es 了。</p>\n<h2 id=\"JVM-FULL-GC-的几种情形\"><a href=\"#JVM-FULL-GC-的几种情形\" class=\"headerlink\" title=\"JVM FULL GC 的几种情形\"></a><a href=\"#jvm-full-gc-%E7%9A%84%E5%87%A0%E7%A7%8D%E6%83%85%E5%BD%A2\"></a>JVM FULL GC 的几种情形</h2><p><strong>Scroll 导致 FullGC</strong></p>\n<p>一些用户使用 scroll 做分页查询或者用 scroll 导出数据的时候，经常把 scroll 的超时时间设置的比较长，比如设置为 1 天，在这种情况下 es 后端会为这个 scroll 一直保存对应的 search context，每个 search context 都对应了 lucene 的 searcher，此时 searcher 一直不释放导致 lucene merge 完的文件也不删除，一些 leafreader， fst 等都长期在 JVM 里导致最终随着 search context 越来越多导致了 FullGC。用户可以使用以下 2 个 API 来查看和清除这些 Context。</p>\n<pre><code>GET /_nodes/stats/indices/search\nDELETE /_search/scroll/_all\n</code></pre>\n<p><strong>查询导致 FullGC</strong></p>\n<p>用户在查询时将结果集的 from+size 设置的太大，比如 size&#x3D;Integer.MAX_VALUE 导致的，目前 ES 会根据设置的这个 from+size 开辟一个 priority queue，当并发量大时，内存会分配不过来这么多非常大的 queue，导致 FULL GC，甚至 OOM。</p>\n<p><strong>aggregation 导致 FullGC</strong></p>\n<p>用户在执行类似 terms agg 时，如果不同的值非常多，最终会导致产生很多 bucket，比如几千万个 bucket，这些 bucket 也会在内存里，最终导致 fullgc。</p>\n<h2 id=\"如何提升导入性能\"><a href=\"#如何提升导入性能\" class=\"headerlink\" title=\"如何提升导入性能\"></a><a href=\"#%E5%A6%82%E4%BD%95%E6%8F%90%E5%8D%87%E5%AF%BC%E5%85%A5%E6%80%A7%E8%83%BD\"></a>如何提升导入性能</h2><p><strong>减少副本数，增加 refresh 间隔</strong></p>\n<pre><code>PUT /index_name/_settings\n&#123;\n      &quot;index.number_of_replicas&quot;: 0,\n         &quot;index.refresh_interval&quot;: &quot;10s&quot;\n&#125; \n</code></pre>\n<p>ES 的多副本机制在写入时会向多个副本都发送原始的 json 文档，然后在多个副本上分别进行分词，建立索引等操作。由于导入是 CPU 密集型操作，所以把 replica 数目改成 0，可以减少 CPU 使用率，当导入完毕后，把 replica 数目改回，这样就是直接拷贝物理文件了，速度会比较快。</p>\n<p>refresh interal 是用来控制多久把内存里的数据刷出 segment 的，es 会对刷出的 segment 进行 merge，如果 merge 不过来 es 会阻止写入。所以把 refresh interval 调大，也可以把刷出的 segment 变大，降低 merge 的频率，提升导入性能。 <strong>增大 index 的导入速度限制</strong></p>\n<pre><code>PUT /_cluster/settings\n&#123;\n      &quot;persistent&quot; : &#123;\n             &quot;indices.store.throttle.max_bytes_per_sec&quot; : &quot;200mb&quot;\n      &#125;\n&#125;\n</code></pre>\n<p>ES 在写入数据的时候会有速度的限制，防止占用过多的磁盘 IO，如果集群的导入比较大而查询比较少，那么可以把这个速度限制调大。</p>\n<h2 id=\"集群配置问题\"><a href=\"#集群配置问题\" class=\"headerlink\" title=\"集群配置问题\"></a><a href=\"#%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE%E9%97%AE%E9%A2%98\"></a>集群配置问题</h2><ul>\n<li><p>需要使用 oracle JDK 1.8 以上版本。</p>\n</li>\n<li><p>设置最大文件数：</p>\n<pre><code> 修改 /etc/security/limits.conf ： \n\n  *　　soft　　nofile　　65536\n\n  *　　hard　　nofile　　65536\n</code></pre>\n</li>\n<li><p>增加 mmap counts ： 修改 &#x2F;etc&#x2F;sysctl.conf ：</p>\n<pre><code> vm.max_map_count=262144\n    \n        然后执行： sysctl -p\n</code></pre>\n</li>\n</ul>\n<h2 id=\"集群重启问题\"><a href=\"#集群重启问题\" class=\"headerlink\" title=\"集群重启问题\"></a><a href=\"#%E9%9B%86%E7%BE%A4%E9%87%8D%E5%90%AF%E9%97%AE%E9%A2%98\"></a>集群重启问题</h2><p>在一些情况下（比如修改配置文件），我们希望重启集群，重启集群可以是一台台的重启，也可以是整个集群重启，重启 Es 的时候，可能会引起数据的重分布，下面就这两种情况分别介绍如何重启服务。</p>\n<p><strong>整个集群重启</strong></p>\n<ul>\n<li><p>把整个集群设置为只读状态</p>\n<pre><code> PUT /_cluster/settings\n        &#123;\n            &quot;persistent&quot;: &#123;\n                &quot;cluster.blocks.read_only&quot;:true\n            &#125;\n        &#125;\n        <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-   把节点内存的数据全部 flush 到硬盘上</span><br><span class=\"line\">-   把所有的 es 节点重启</span><br><span class=\"line\">-   当集群 green 之后，把集群修改为可写入状态</span><br><span class=\"line\"></span><br><span class=\"line\">         PUT /_cluster/settings</span><br><span class=\"line\">        \t&#123;</span><br><span class=\"line\">        \t    <span class=\"string\">&quot;persistent&quot;</span>: &#123;</span><br><span class=\"line\">        \t        <span class=\"string\">&quot;cluster.blocks.read_only&quot;</span>:<span class=\"literal\">false</span></span><br><span class=\"line\">        \t    &#125;</span><br><span class=\"line\">        \t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    **一台台重启**</span><br><span class=\"line\"></span><br><span class=\"line\">这种方式重启服务不会中断，适用于线上服务。</span><br><span class=\"line\"></span><br><span class=\"line\">-   禁止分片分配，这样我们关闭一台 Es 服务的时候，分片不会重分布。 `PUT /_cluster/settings &#123;<span class=\"string\">&quot;transient&quot;</span> : &#123; <span class=\"string\">&quot;cluster.routing.allocation.enable&quot;</span> : <span class=\"string\">&quot;none&quot;</span>&#125; &#125;`</span><br><span class=\"line\">-   关闭单个节点，修改配置或者替换 jar 包，启动节点</span><br><span class=\"line\">-   开启分片重分布</span><br><span class=\"line\"></span><br><span class=\"line\">         PUT /_cluster/settings</span><br><span class=\"line\">        \t&#123;</span><br><span class=\"line\">            \t<span class=\"string\">&quot;transient&quot;</span> : &#123;</span><br><span class=\"line\">                \t<span class=\"string\">&quot;cluster.routing.allocation.enable&quot;</span> : <span class=\"string\">&quot;all&quot;</span></span><br><span class=\"line\">            \t&#125;</span><br><span class=\"line\">        \t&#125;</span><br></pre></td></tr></table></figure>\n</code></pre>\n</li>\n<li><p>等待集群 green 后，重复执行 1-3 步，直到所有的节点都修改完配置为止。</p>\n</li>\n</ul>\n<h2 id=\"禁用-field-names\"><a href=\"#禁用-field-names\" class=\"headerlink\" title=\"禁用_field_names\"></a><a href=\"#%E7%A6%81%E7%94%A8_field_names\"></a>禁用_field_names</h2><p><code>_field_names</code>字段是 Elasticsearch 的内部的一个元数据字段。该字段会索引文档内的每个字段的名字 (除了字段值为 null 的字段名字); 这个字段存在的意义主要是执行 Elasticsarech <code>exists</code> query，Elasticsearch 对该字段只做了索引处理，没有存储该字段，6.3 版本以后该字段只会索引没有禁掉 doc_value 和 norms 的字段，建议业务不使用<code>exists</code> 查询的情况下 disable 该字段，能够少量的减少倒排表的占用的存储空间，可能会适当增强 pagecache 的利用</p>\n<pre><code> PUT index\n &#123;\n   &quot;mappings&quot;: &#123;\n     &quot;_doc&quot;: &#123;\n       &quot;_field_names&quot;: &#123;\n         &quot;enabled&quot;: false\n       &#125;\n     &#125;\n   &#125;\n &#125;\n</code></pre>\n<h2 id=\"导入数据发现越来越慢的几种情形\"><a href=\"#导入数据发现越来越慢的几种情形\" class=\"headerlink\" title=\"导入数据发现越来越慢的几种情形\"></a><a href=\"#%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E5%8F%91%E7%8E%B0%E8%B6%8A%E6%9D%A5%E8%B6%8A%E6%85%A2%E7%9A%84%E5%87%A0%E7%A7%8D%E6%83%85%E5%BD%A2\"></a>导入数据发现越来越慢的几种情形</h2><p><strong>导入数据中包含 update</strong></p>\n<p>Es 的 update 实际上是先读取数据然后更改后，再写入的，当写入的数据越来越多的时候，读取数据就会比较慢，写入也就逐渐变慢了。</p>\n<h2 id=\"控制-index-在节点上的数量\"><a href=\"#控制-index-在节点上的数量\" class=\"headerlink\" title=\"控制 index 在节点上的数量\"></a><a href=\"#%E6%8E%A7%E5%88%B6index%E5%9C%A8%E8%8A%82%E7%82%B9%E4%B8%8A%E7%9A%84%E6%95%B0%E9%87%8F\"></a>控制 index 在节点上的数量</h2><p>默认情况下，ES 集群会尽可能将所有节点上的 index 和 shard 的数量进行 balance，但是一些特殊情况下，可能会造成某一个 index 的 shard 过多的集中在少量的节点上，这时候可以通过设置集群中每个节点存放 index shard 的个数：</p>\n<pre><code>PUT &#123;index名字&#125;/_settings\n&#123;\n   &quot;index.routing.allocation.total_shards_per_node&quot;: 10\n&#125;\n</code></pre>\n<h2 id=\"控制索引的分片数量和副本数量\"><a href=\"#控制索引的分片数量和副本数量\" class=\"headerlink\" title=\"控制索引的分片数量和副本数量\"></a><a href=\"#%E6%8E%A7%E5%88%B6%E7%B4%A2%E5%BC%95%E7%9A%84%E5%88%86%E7%89%87%E6%95%B0%E9%87%8F%E5%92%8C%E5%89%AF%E6%9C%AC%E6%95%B0%E9%87%8F\"></a>控制索引的分片数量和副本数量</h2><p>不修改参数的情况下，一个 index 一共有 5 个分片，2 个副本（包括主分片）, 可以通过修改 index 的参数来控制：</p>\n<pre><code>PUT /&#123;index名字&#125;\n&#123;\n    &quot;settings&quot;: &#123;\n        &quot;number_of_shards&quot;: 20,\n        &quot;number_of_replicas&quot;: 2\n    &#125;\n&#125;\n\nnumber_of_shards: 分片个数，创建完index后不可修改，需在创建的时候指定\nnumber_of_replicas： 副本个数，不包括主分片\n</code></pre>\n<h2 id=\"当集群处于恢复状态的时候，恢复速度可能会比较慢\"><a href=\"#当集群处于恢复状态的时候，恢复速度可能会比较慢\" class=\"headerlink\" title=\"当集群处于恢复状态的时候，恢复速度可能会比较慢\"></a><a href=\"#%E5%BD%93%E9%9B%86%E7%BE%A4%E5%A4%84%E4%BA%8E%E6%81%A2%E5%A4%8D%E7%8A%B6%E6%80%81%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E6%81%A2%E5%A4%8D%E9%80%9F%E5%BA%A6%E5%8F%AF%E8%83%BD%E4%BC%9A%E6%AF%94%E8%BE%83%E6%85%A2\"></a>当集群处于恢复状态的时候，恢复速度可能会比较慢</h2><p>当前正在恢复的索引分片可以通过</p>\n<pre><code>GET /_recovery?active_only=true \n</code></pre>\n<p>查看，默认情况一个节点同时恢复的个数为 4，包括 2 个作为 source 节点，2 个作为 target 节点，当分片个数非常多的时候可能会恢复的很慢，恢复的时候默认是有限速的最大 40mb, 这时候可以通过设置集群参数：</p>\n<pre><code>curl -XPUT &quot;host:port/_cluster/settings&quot; -d&#39;\n&#123;\n    &quot;transient&quot;: &#123;\n        &quot;cluster.routing.allocation.node_concurrent_recoveries&quot;: 8,\n        &quot;indices.recovery.max_bytes_per_sec&quot;: &quot;120mb&quot;\n    &#125;\n&#125;&#39;\n\nindices.recovery.max_bytes_per_sec： 节点恢复的最大带宽，这个设置应该小于当前网络带宽，避免影响其他网络服务\ncluster.routing.allocation.node_concurrent_recoveries： 节点作为source node或target node同时恢复的最大个数\n</code></pre>\n<h2 id=\"磁盘满了之后如何恢复\"><a href=\"#磁盘满了之后如何恢复\" class=\"headerlink\" title=\"磁盘满了之后如何恢复\"></a><a href=\"#%E7%A3%81%E7%9B%98%E6%BB%A1%E4%BA%86%E4%B9%8B%E5%90%8E%E5%A6%82%E4%BD%95%E6%81%A2%E5%A4%8D\"></a>磁盘满了之后如何恢复</h2><p>当 Es 的 DataNode 的磁盘使用率达到一定的阈值（95%）之后，Es 会阻止继续写入，Es 会在所有的 Index 上加一个 block，当用户继续写入的时候会收到以下错误</p>\n<pre><code>cluster_block_exception [FORBIDDEN/12/index read-only / allow delete (api)];\n</code></pre>\n<p>此时用户必须释放磁盘空间才能解决问题，释放磁盘空间有 2 种办法：</p>\n<ul>\n<li>删除不用的 Index</li>\n<li>降低 Index 的副本的数目，比如把 replica 数目从 2 降到 1.</li>\n</ul>\n<p>当释放完毕磁盘空间之后，Es 并不会自动把 block 去掉，此时用户仍然无法写入数据，需要执行以下命令：</p>\n<pre><code>curl -XPUT &quot;host:port/_all/_settings&quot; -d &#39;\n&#123;\n    &quot;index.blocks.read_only_allow_delete&quot;: null\n&#125;&#39;\n</code></pre>\n<p> <a href=\"https://cloud.baidu.com/doc/BES/s/Zjyzk4k1w\">https://cloud.baidu.com/doc/BES/s/Zjyzk4k1w</a></p>\n","text":"Elasticsearch系统常见问题如何查看 Es 安装了哪些插件可以使用下面这个 API，会列出每个节点安装的插件列表。 线程池队列满导致错误在这种场景下 ...","permalink":"/post/MIDDLEWARE/Elasticsearch系统常见问题","photos":[],"count_time":{"symbolsCount":"8.7k","symbolsTime":"8 mins."},"categories":[{"name":"shard","slug":"shard","count":1,"path":"api/categories/shard.json"},{"name":"MIDDLEWARE","slug":"shard/MIDDLEWARE","count":1,"path":"api/categories/shard/MIDDLEWARE.json"}],"tags":[{"name":"search","slug":"search","count":2,"path":"api/tags/search.json"},{"name":"index","slug":"index","count":1,"path":"api/tags/index.json"},{"name":"segment","slug":"segment","count":1,"path":"api/tags/segment.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Elasticsearch%E7%B3%BB%E7%BB%9F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98\"><span class=\"toc-text\">Elasticsearch系统常见问题</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8B-Es-%E5%AE%89%E8%A3%85%E4%BA%86%E5%93%AA%E4%BA%9B%E6%8F%92%E4%BB%B6\"><span class=\"toc-text\">如何查看 Es 安装了哪些插件</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%BA%BF%E7%A8%8B%E6%B1%A0%E9%98%9F%E5%88%97%E6%BB%A1%E5%AF%BC%E8%87%B4%E9%94%99%E8%AF%AF\"><span class=\"toc-text\">线程池队列满导致错误</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Too-Many-Open-Files-%E7%9A%84%E9%94%99%E8%AF%AF\"><span class=\"toc-text\">Too Many Open Files 的错误</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Es-%E4%B8%AD%E4%B8%80%E4%B8%AA%E5%88%86%E7%89%87%E4%B8%80%E8%88%AC%E8%AE%BE%E7%BD%AE%E5%A4%9A%E5%A4%A7\"><span class=\"toc-text\">Es 中一个分片一般设置多大</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%BD%93%E9%9B%86%E7%BE%A4%E4%B8%BA-red-%E6%88%96%E8%80%85-yellow-%E7%9A%84%E6%97%B6%E5%80%99%E6%80%8E%E4%B9%88%E5%8A%9E\"><span class=\"toc-text\">当集群为 red 或者 yellow 的时候怎么办</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%A6%82%E4%BD%95-cancel-%E6%8E%89%E6%85%A2%E6%9F%A5%E8%AF%A2\"><span class=\"toc-text\">如何 cancel 掉慢查询</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#PageCache-%E5%9C%A8%E6%9F%A5%E8%AF%A2%E4%B8%AD%E7%9A%84%E4%BD%9C%E7%94%A8%E5%BE%88%E5%A4%A7\"><span class=\"toc-text\">PageCache 在查询中的作用很大</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%A6%81%E7%94%A8%E6%9D%83%E9%99%90%E9%AA%8C%E8%AF%81\"><span class=\"toc-text\">禁用权限验证</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%94%AF%E6%8C%81%E7%9A%84-Client-%E7%9A%84%E7%B1%BB%E5%9E%8B\"><span class=\"toc-text\">支持的 Client 的类型</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Es-%E6%98%AF%E5%90%A6%E6%94%AF%E6%8C%81-Spark-%E5%92%8C-Hadoop-%E6%9D%A5%E5%86%99%E5%85%A5%E6%88%96%E8%80%85%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE\"><span class=\"toc-text\">Es 是否支持 Spark 和 Hadoop 来写入或者读取数据</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#JVM-FULL-GC-%E7%9A%84%E5%87%A0%E7%A7%8D%E6%83%85%E5%BD%A2\"><span class=\"toc-text\">JVM FULL GC 的几种情形</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%A6%82%E4%BD%95%E6%8F%90%E5%8D%87%E5%AF%BC%E5%85%A5%E6%80%A7%E8%83%BD\"><span class=\"toc-text\">如何提升导入性能</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE%E9%97%AE%E9%A2%98\"><span class=\"toc-text\">集群配置问题</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E9%9B%86%E7%BE%A4%E9%87%8D%E5%90%AF%E9%97%AE%E9%A2%98\"><span class=\"toc-text\">集群重启问题</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%A6%81%E7%94%A8-field-names\"><span class=\"toc-text\">禁用_field_names</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E5%8F%91%E7%8E%B0%E8%B6%8A%E6%9D%A5%E8%B6%8A%E6%85%A2%E7%9A%84%E5%87%A0%E7%A7%8D%E6%83%85%E5%BD%A2\"><span class=\"toc-text\">导入数据发现越来越慢的几种情形</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%8E%A7%E5%88%B6-index-%E5%9C%A8%E8%8A%82%E7%82%B9%E4%B8%8A%E7%9A%84%E6%95%B0%E9%87%8F\"><span class=\"toc-text\">控制 index 在节点上的数量</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%8E%A7%E5%88%B6%E7%B4%A2%E5%BC%95%E7%9A%84%E5%88%86%E7%89%87%E6%95%B0%E9%87%8F%E5%92%8C%E5%89%AF%E6%9C%AC%E6%95%B0%E9%87%8F\"><span class=\"toc-text\">控制索引的分片数量和副本数量</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%BD%93%E9%9B%86%E7%BE%A4%E5%A4%84%E4%BA%8E%E6%81%A2%E5%A4%8D%E7%8A%B6%E6%80%81%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E6%81%A2%E5%A4%8D%E9%80%9F%E5%BA%A6%E5%8F%AF%E8%83%BD%E4%BC%9A%E6%AF%94%E8%BE%83%E6%85%A2\"><span class=\"toc-text\">当集群处于恢复状态的时候，恢复速度可能会比较慢</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%A3%81%E7%9B%98%E6%BB%A1%E4%BA%86%E4%B9%8B%E5%90%8E%E5%A6%82%E4%BD%95%E6%81%A2%E5%A4%8D\"><span class=\"toc-text\">磁盘满了之后如何恢复</span></a></li></ol></li></ol>","author":{"name":"dandeliono","slug":"blog-author","avatar":"https://avatars.githubusercontent.com/u/29496357","link":"/","description":"永远相信美好的事情即将发生","socials":{"github":"https://github.com/dandeliono","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{"title":"Linux 命令行编辑快捷键","uid":"a94b0501505e8b946dbe5622c7a78b56","slug":"LINUX/Linux 命令行编辑快捷键","date":"2021-11-26T16:59:24.000Z","updated":"2025-12-05T01:47:01.478Z","comments":true,"path":"api/articles/LINUX/Linux 命令行编辑快捷键.json","keywords":"XuGuangSheng","cover":"/covers/linux.jpg","text":"Linux 命令行编辑快捷键Linux 命令行编辑快捷键初学者在 Linux 命令窗口（终端）敲命令时，肯定觉得通过输入一串一串的字符的方式来控制计算是效率很低...","permalink":"/post/LINUX/Linux 命令行编辑快捷键","photos":[],"count_time":{"symbolsCount":"1.1k","symbolsTime":"1 mins."},"categories":[{"name":"Linux","slug":"Linux","count":1,"path":"api/categories/Linux.json"},{"name":"LINUX","slug":"Linux/LINUX","count":1,"path":"api/categories/Linux/LINUX.json"}],"tags":[{"name":"命令行编辑快捷键","slug":"命令行编辑快捷键","count":1,"path":"api/tags/命令行编辑快捷键.json"},{"name":"初学者在","slug":"初学者在","count":1,"path":"api/tags/初学者在.json"},{"name":"命令窗口","slug":"命令窗口","count":1,"path":"api/tags/命令窗口.json"}],"author":{"name":"dandeliono","slug":"blog-author","avatar":"https://avatars.githubusercontent.com/u/29496357","link":"/","description":"永远相信美好的事情即将发生","socials":{"github":"https://github.com/dandeliono","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"docker-compose部署flink集群","uid":"96cd93f7633628e16d6fdcc58320aac4","slug":"OCI/docker-compose部署flink集群","date":"2021-11-13T11:41:36.000Z","updated":"2025-12-05T01:47:55.274Z","comments":true,"path":"api/articles/OCI/docker-compose部署flink集群.json","keywords":"XuGuangSheng","cover":"/covers/docker-composeflink.jpg","text":"docker-compose部署flink集群flink 集群部署 拉取 flink 镜像 12docker pull flink 自定义创建目录（例如 / u...","permalink":"/post/OCI/docker-compose部署flink集群","photos":[],"count_time":{"symbolsCount":"12k","symbolsTime":"11 mins."},"categories":[{"name":"flink","slug":"flink","count":2,"path":"api/categories/flink.json"},{"name":"OCI","slug":"flink/OCI","count":1,"path":"api/categories/flink/OCI.json"}],"tags":[{"name":"docker","slug":"docker","count":4,"path":"api/tags/docker.json"},{"name":"compose","slug":"compose","count":1,"path":"api/tags/compose.json"},{"name":"集群","slug":"集群","count":1,"path":"api/tags/集群.json"}],"author":{"name":"dandeliono","slug":"blog-author","avatar":"https://avatars.githubusercontent.com/u/29496357","link":"/","description":"永远相信美好的事情即将发生","socials":{"github":"https://github.com/dandeliono","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}