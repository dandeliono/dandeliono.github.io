{"title":"ElasticSearch-Aggregations-GroupBy-实现源码分析","uid":"7fb39e737e8e188c4592d757c3adaa67","slug":"MIDDLEWARE/ElasticSearch-Aggregations-GroupBy-实现源码分析","date":"2022-07-06T09:43:40.000Z","updated":"2025-09-30T03:26:45.144Z","comments":true,"path":"api/articles/MIDDLEWARE/ElasticSearch-Aggregations-GroupBy-实现源码分析.json","keywords":"XuGuangSheng","cover":"/covers/elasticsearch-aggregations-groupby.jpg","content":"<h1 id=\"ElasticSearch-Aggregations-GroupBy-实现源码分析\"><a href=\"#ElasticSearch-Aggregations-GroupBy-实现源码分析\" class=\"headerlink\" title=\"ElasticSearch-Aggregations-GroupBy-实现源码分析\"></a>ElasticSearch-Aggregations-GroupBy-实现源码分析</h1><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>在前文 <a href=\"http://www.jianshu.com/p/56ad2b7e27b7\">ElasticSearch Aggregations 分析</a> 中，我们提及了 【Aggregation Bucket 的实现】，然而只是用文字简要描述了原理。今天我们会举个实际 groupBy 的例子进行剖析，让大家对 ElasticSearch Aggregations 的工作原理有更深入的理解</p></blockquote>\n<h2 id=\"准备工作\"><a href=\"#准备工作\" class=\"headerlink\" title=\"准备工作\"></a>准备工作</h2><ul>\n<li><p>为了方便调试，我对索引做了如下配置</p>\n<p>{<br>  “mappings”: {<br>“my_type”: {<br>  “properties”: {<br>    “newtype”: {<br>      “type”:       “string”,<br>      “index”:      “not_analyzed”<br>    },<br>    “num”: {<br>      “type”:       “integer”<br>    }<br>  }<br>}<br>  },<br>   “settings” : {<br>    “index” : {<br>        “number_of_shards” : 1,<br>        “number_of_replicas” : 0<br>    }<br>}<br>}</p>\n</li>\n</ul>\n<p>这样只有一个分片，方便 IDE 的跟踪，也算是个看源码的技巧</p>\n<ul>\n<li><p>数据</p>\n<p>{<br>“user” : “kimchy”,<br>“post_date” : “2009-11-15T14:12:12”,<br>“newtype”: “abc”,<br>“message” : “trying out Elasticsearch”,<br>“num” : 10<br>}</p>\n</li>\n</ul>\n<h2 id=\"查询语句\"><a href=\"#查询语句\" class=\"headerlink\" title=\"查询语句\"></a>查询语句</h2><p>假定的查询如下：</p>\n<pre><code>&#123;\n    &quot;from&quot;: 0,\n    &quot;size&quot;: 0,\n    &quot;_source&quot;: &#123;\n        &quot;includes&quot;: [\n            &quot;AVG&quot;\n        ],\n        &quot;excludes&quot;: []\n    &#125;,\n    &quot;aggregations&quot;: &#123;\n        &quot;newtype&quot;: &#123;\n            &quot;terms&quot;: &#123;\n                &quot;field&quot;: &quot;newtype&quot;,\n                &quot;size&quot;: 200\n            &#125;,\n            &quot;aggregations&quot;: &#123;\n                &quot;AVG(num)&quot;: &#123;\n                    &quot;avg&quot;: &#123;\n                        &quot;field&quot;: &quot;num&quot;\n                    &#125;\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n&#125; \n</code></pre>\n<p>其语义类似这个 sql 语句：</p>\n<pre><code>SELECT avg(num) FROM twitter group by newtype \n</code></pre>\n<p>也就是按 newtype 字段进行 group by, 然后对 num 求平均值。在我们实际的业务系统中，这种统计需求也是最多的。</p>\n<h2 id=\"Phase-概念\"><a href=\"#Phase-概念\" class=\"headerlink\" title=\"Phase 概念\"></a>Phase 概念</h2><p>在查询过程中，ES 是将整个查询分成几个阶段的，大体如下：</p>\n<ul>\n<li>QueryPhase</li>\n<li>rescorePhase</li>\n<li>suggestPhase</li>\n<li>aggregationPhase</li>\n<li>FetchPhase</li>\n</ul>\n<p>对于全文检索，可能还有 DFSPhase。</p>\n<p>顺带提一点，Spark SQL + ES 的组合，最影响响应时间的地方其实是 Fetch original source 。</p>\n<p>而对于这些 Phase, 并不是一个链路的模式，而是在某个 Phase 调用另外一个 Phase。这个在源码中也很明显，我们看如下一段代码：</p>\n<pre><code> //创建聚合需要的AggregationContext,\n     //里面包含了各个Aggregator\n      aggregationPhase.preProcess(searchContext);\n\n       //实际query,还有聚合操作其实是在这部完成的\n        boolean rescore = execute(searchContext, searchContext.searcher());\n\n        //如果是全文检索，并且需要打分\n        if (rescore) &#123; // only if we do a regular search\n            rescorePhase.execute(searchContext);\n        &#125;\n        suggestPhase.execute(searchContext);\n        //获取聚合结果\n        aggregationPhase.execute(searchContext);       \n        &#125; \n</code></pre>\n<h2 id=\"Aggregation-的相关概念\"><a href=\"#Aggregation-的相关概念\" class=\"headerlink\" title=\"Aggregation 的相关概念\"></a>Aggregation 的相关概念</h2><p>要了解具体是如何实现聚合功能的，则需要了解 ES 的 aggregator 相关的概念。大体有五个：</p>\n<ul>\n<li>AggregatorFactory （典型的工厂模式）负责创建 Aggregator 实例</li>\n<li>Aggregator (负责提供 collector, 并且提供具体聚合逻辑的类)</li>\n<li>Aggregations (聚合结果)</li>\n<li>PipelineAggregator (对聚合结果进一步处理)</li>\n<li>Aggregator 的嵌套，比如 示例中的 AvgAggregator 就是根据 GlobalOrdinalsStringTermsAggregator 的以 bucket 为维度，对相关数据进行操作. 这种嵌套结构也是</li>\n<li>Bucket 其实就是被 groupBy 字段的数字表示形式。用数字表示，可以节省对应字段列式存储的空间，并且提高性能。</li>\n</ul>\n<h2 id=\"Aggregations-实现的机制\"><a href=\"#Aggregations-实现的机制\" class=\"headerlink\" title=\"Aggregations 实现的机制\"></a>Aggregations 实现的机制</h2><p>我们知道，无论检索亦或是聚合查询，本质上都需要转化到 Lucene 里的 Collector，以上面的案例为例, 其实由两个 Collector 完成最后的计算：</p>\n<ul>\n<li>TotalHitCountCollecotr</li>\n<li>GlobalOrdinalsStringTermsAggregator(里面还有个 Aggregator)</li>\n</ul>\n<p>因为我们没有定义过滤条件，所以最后的 Query 是个 MatchAllQuery，之后基于这个基础上，这两个 collector 完成对应的计算。通常，这两个 Collector 会被 wrap 成一个新的 MultiCollector ，最终传入 IndexSearcher 的 Collector 就是 MultiCollector。</p>\n<p>根据上面的分析，我们知道示例中的聚合计算完全由 GlobalOrdinalsStringTermsAggregator 负责。</p>\n<h2 id=\"基于-DocValues-实现-groupBy-概览\"><a href=\"#基于-DocValues-实现-groupBy-概览\" class=\"headerlink\" title=\"基于 DocValues 实现 groupBy 概览\"></a>基于 DocValues 实现 groupBy 概览</h2><p>对于每一个 segment, 我们都会为每个列单独存储成一个文件，为了压缩，我们可能会将里面具体的值转换成数字，然后再形成一个字典和数字对应关系的文件。我们进行所谓的 groupBy 操作，以最后进行 Avg 为例子，其实就是维护了两个大数组，</p>\n<pre><code>LongArray counts;//Long数组\nDoubleArray sums; //Double 数组 \n</code></pre>\n<p>counts 是 newtype(我们例子中被 groupby 的字段) 次数统计，对应的数组下标是 newtype(我们已经将 newtype 转化为数字表示了)。我们遍历文档的时候 (MatchAllQuery)，可以获取 doc, 然后根据 doc 到列存文件获取对应的 newtype, 然后给 counts 对应的 newtype +1。 这样我们就知道每个 newtype 出现的次数了。</p>\n<p>这里我们也可以看到，消耗内存的地方取决于 newtype 的数量 (distinct 后)，我们称之为基数。基数过高的话，是比较消耗内存的。</p>\n<p>sums 也是一样的，下标是 newtype 的值，而对应的值则是不断累加 num(我们例子中需要被 avg 的字段)。</p>\n<p>之后就可以遍历两个数组得到结果了，代码大体如下：</p>\n<pre><code>//这里的owningBucketOrd 就是newtype 的数字化表示\npublic double metric(long owningBucketOrd) &#123;\n        if (valuesSource == null || owningBucketOrd &gt;= sums.size()) &#123;\n            return Double.NaN;\n        &#125;\n        return sums.get(owningBucketOrd) / counts.get(owningBucketOrd);\n    &#125; \n</code></pre>\n<h2 id=\"GlobalOrdinalsStringTermsAggregator-x2F-AvgAggregator-组合实现\"><a href=\"#GlobalOrdinalsStringTermsAggregator-x2F-AvgAggregator-组合实现\" class=\"headerlink\" title=\"GlobalOrdinalsStringTermsAggregator&#x2F;AvgAggregator 组合实现\"></a>GlobalOrdinalsStringTermsAggregator&#x2F;AvgAggregator 组合实现</h2><p>GlobalOrdinalsStringTermsAggregator 首先要提供一个 Collector 给主流程，所以其提供了一个 newCollector 方法：</p>\n<pre><code>protected LeafBucketCollector newCollector(\n//DocValue 列式存储的一个API表现\nfinal RandomAccessOrds ords,\n//AvgAggregator提供的Collector\nfinal LeafBucketCollector sub) \n</code></pre>\n<p>接着判定是不是只有一个列文件 (DocValues):</p>\n<pre><code>final SortedDocValues singleValues = DocValues.unwrapSingleton(words);\n//如果singleValues!=null 则是一个，否则有多个列文件 \n</code></pre>\n<p>如果是一个的话：</p>\n<pre><code>public void collect(int doc, long bucket) throws IOException &#123;\n                    assert bucket == 0;\n                    final int ord = singleValues.getOrd(doc);\n                    if (ord &gt;= 0) &#123;\n                        collectExistingBucket(sub, doc, ord);\n                    &#125;\n                &#125;\n//collectExistingBucket\n public final void collectExistingBucket(LeafBucketCollector subCollector, int doc, long bucketOrd) throws IOException &#123;\n        docCounts.increment(bucketOrd, 1);\n        subCollector.collect(doc, bucketOrd);\n    &#125; \n</code></pre>\n<p>通过 doc 拿到 ord(newtype), 然后交给 Avg 的 collector 接着处理, 进入 AvgAggregator 里的 Collector 的 collect 逻辑：</p>\n<pre><code>public void collect(int doc, long bucket) throws IOException &#123;\n                counts = bigArrays.grow(counts, bucket + 1);\n                sums = bigArrays.grow(sums, bucket + 1);\n\n                values.setDocument(doc);\n                final int valueCount = values.count();\n                counts.increment(bucket, valueCount);\n                double sum = 0;\n                for (int i = 0; i &lt; valueCount; i++) &#123;\n                    sum += values.valueAt(i);\n                &#125;\n                sums.increment(bucket, sum);\n            &#125; \n</code></pre>\n<p>这个和我上面的概述中描述是一致的。</p>\n<p>如果是多个 DocValues(此时索引还没有对那些 Segment 做合并)，这个时候会走下面的流程：</p>\n<pre><code>public void collect(int doc, long bucket) throws IOException &#123;\n                    assert bucket == 0;\n                    ords.setDocument(doc);\n                    final int numOrds = ords.cardinality();\n                    for (int i = 0; i &lt; numOrds; i++) &#123;\n                        final long globalOrd = ords.ordAt(i);\n                        collectExistingBucket(sub, doc, globalOrd);\n                    &#125;\n                &#125; \n</code></pre>\n<p>这里的 ords 包括了多个 DocValues 文件, 然后做了全局映射，因为要把文件的下标做映射。为啥要有下标映射呢？因为多个列文件 (DocValues) 的全集才具有完整的 newtype，但是每个列文件都是从 0 开始递增的。现在要扩张到一个 global 的空间上。 ords.cardinality() 拿到了列文件 (DocValues) 的数目，然后对每个文件都处理一遍，通过 ords.ordAt(i) 拿到 newtype 的全局下标，这个时候就可以继续交给 Avg 完成了。</p>\n<p>到这个阶段，我们其实已经算好了每个 newtype 出现的次数，以及 num 的累计值，也就是我们前面提到的两个数组。</p>\n<h2 id=\"BuildAggregation\"><a href=\"#BuildAggregation\" class=\"headerlink\" title=\"BuildAggregation\"></a>BuildAggregation</h2><p>最终我们是要把这个数据输出输出的，不论是输出给别的 ES 节点，还是直接输出给调用方。所以有个 BuildAggregation 的过程，可以根据名字进行直观的了解。</p>\n<p>考虑到内存问题，ES 允许你设置一些 Threshhold, 然后通过 BucketPriorityQueue(优先队列) 来完成实际的数据收集以及排序 (默认按文档出现次数排序)。 里面的元素是 OrdBucket，OrdBucket 包含了几个值：</p>\n<pre><code>globalOrd： 全局下标\nbucketOrd： 在所属文件里的下标\ndocCount : 文档出现的次数 \n</code></pre>\n<p>接着取出 topN 的对象，放到 InternalTerms.Bucket[] 数组中。然后遍历该数组，调用子 Aggregator 的 buildAggregation 方法，这里的子 Aggregator 是 AvgAggregator , 每个 Bucket(newtype) 就获取到一个 avg aggregations 了，该 aggregations 通过 InternalAggregations 包裹，InternalAggregations 包含了一个 reduce 方法，该方法会调用具体 InternalAggregation 的 doReduce 方法，比如 AvgAggregator 就有自己的 reduce 方法。说这个主要给下一小结做铺垫。</p>\n<p>最后会被包装成 StringTerms , 然后就可以序列化成 JSON 格式，基本就是你在接口上看到的样子了。</p>\n<h2 id=\"多分片聚合结果合并\"><a href=\"#多分片聚合结果合并\" class=\"headerlink\" title=\"多分片聚合结果合并\"></a>多分片聚合结果合并</h2><p>前面我们讨论的，都是基于一个分片，但是最终是要把结果数据进行 Merge 的。 这个功能是由 SearchPhaseController 对象来完成，大体如下：</p>\n<pre><code>sortedShardList = searchPhaseController.sortDocs(useScroll, firstResults);\n\nfinal InternalSearchResponse internalResponse = searchPhaseController.merge(sortedShardList, firstResults,\n                    firstResults, request); \n</code></pre>\n<p>其中 merge 动作是按分类进行 merge 的，比如：</p>\n<ul>\n<li>counter(计数, 譬如 total_hits)</li>\n<li>hits</li>\n<li>aggregations</li>\n<li>suggest</li>\n<li>profile （性能相关的数据）</li>\n</ul>\n<p>这里我们只关注 aggregations 的 merge</p>\n<pre><code> // merge addAggregation\n        InternalAggregations aggregations = null;\n        if (!queryResults.isEmpty()) &#123;\n            if (firstResult.aggregations() != null &amp;&amp; firstResult.aggregations().asList() != null) &#123;\n                List&lt;InternalAggregations&gt; aggregationsList = new ArrayList&lt;&gt;(queryResults.size());\n                for (AtomicArray.Entry&lt;? extends QuerySearchResultProvider&gt; entry : queryResults) &#123;\n                    aggregationsList.add((InternalAggregations) entry.value.queryResult().aggregations());\n                &#125;\n                aggregations = InternalAggregations.reduce(aggregationsList, new ReduceContext(bigArrays, scriptService, headersContext));\n            &#125;\n        &#125; \n</code></pre>\n<p>代码有点长，核心是</p>\n<pre><code>InternalAggregations.reduce(.....) \n</code></pre>\n<p>里面实际的逻辑也是比较简单直观的。会调用 InternalTerms 的 reduce 方法做 merge, 但是不同的类型的 Aggregator 产生 Aggregations 合并逻辑是不一样的，所以会委托给对应实现。比如 GlobalOrdinalsStringTermsAggregator 则会委托给 InternalTerms 的 doReduce 方法，而如 AvgAggregator 会委托给 InternalAvg 的 doReduce。 这里就不展开。未来会单独出一片文章讲解。</p>\n<h2 id=\"附录\"><a href=\"#附录\" class=\"headerlink\" title=\"附录\"></a>附录</h2><p>这里我们再额外讲讲 ValueSource (ES 对 FieldData&#x2F;DocValues 的抽象)。</p>\n<p>前文我们提到，大部分 Aggregator 都是依赖于 FieldData&#x2F;DocValues 来实现的，而 ValueSource 则是他们在 ES 里的表示。所以了解他们是很有必要的。ValuesSource 全类名是：</p>\n<pre><code> org.elasticsearch.search.aggregations.support.ValuesSource \n</code></pre>\n<p>该类就是 ES 为了管理 DocValues 而封装的。它是一个抽象类，内部还有很多实现类，Bytes,WithOrdinals,FieldData,Numeric,LongValues 等等。这些都是对特定类型 DocValues 类型的 ES 表示。</p>\n<p>按上面我们的查询示例来看，<code>newtype</code> 字段对应的是</p>\n<pre><code> org.elasticsearch.search.aggregations.support.ValuesSource.Bytes.WithOrdinals.FieldData \n</code></pre>\n<p>对象。这个对象是 ES 对 Lucene String 类型的 DocValues 的一个表示。 你会发现在 ValueSource 类里，有不同的 FieldData。不同的 FieldData 可能继承自不同基类从而表示不同类型的数据。在现在这个 FieldData 里面有一个对象：</p>\n<pre><code>protected final IndexOrdinalsFieldData indexFieldData; \n</code></pre>\n<p>该对象在 newtype(我们示例中的字段) 是 String 类型的时候，对应的是实现类是</p>\n<pre><code>org.elasticsearch.index.fielddata.plain.SortedSetDVOrdinalsIndexFieldData \n</code></pre>\n<p>该对象的大体作用是，构建出 DocValue 的 ES 的 Wraper。</p>\n<p>具体代码如下：</p>\n<pre><code>@Overridepublic AtomicOrdinalsFieldData load(LeafReaderContext context) &#123;    \nreturn new SortedSetDVBytesAtomicFieldData(\n   context.reader(),\n   fieldNames.indexName());\n&#125;\n//或者通过loadGlobal方法得到\n//org.elasticsearch.index.fielddata.ordinals.InternalGlobalOrdinalsIndexFieldData \n</code></pre>\n<p>以第一种情况为例，上面的代码 new 了一个新的<code>org.elasticsearch.index.fielddata.AtomicOrdinalsFieldData</code>对象, 该对象的一个实现类是<code>SortedSetDVBytesAtomicFieldData</code> 。 这个对象和 Lucene 的 DocValues 完成最后的对接：</p>\n<pre><code> @Override\n    public RandomAccessOrds getOrdinalsValues() &#123;\n        try &#123;\n            return FieldData.maybeSlowRandomAccessOrds(DocValues.getSortedSet(reader, field));\n        &#125; catch (IOException e) &#123;\n            throw new IllegalStateException(&quot;cannot load docvalues&quot;, e);\n        &#125;\n    &#125; \n</code></pre>\n<p>我们看到，通过 Reader 获取到最后的列就是在该类里的 getOrdinalsValues 方法里实现的。</p>\n<p>该方法最后返回的 RandomAccessOrds 就是 Lucene 的 DocValues 实现了。</p>\n<p>分析了这么多，所有的逻辑就浓缩在<code>getLeafCollector</code> 的第一行代码上。globalOrds 的类型是 RandomAccessOrds，并且是直接和 Lucene 对应上了。</p>\n<pre><code>globalOrds = valuesSource.globalOrdinalsValues(cox); \n</code></pre>\n<p>getLeafCollector 最后 newCollector 的规则如下：</p>\n<pre><code> protected LeafBucketCollector newCollector(final RandomAccessOrds ords, final LeafBucketCollector sub) &#123;\n        grow(ords.getValueCount());\n        final SortedDocValues singleValues = DocValues.unwrapSingleton(ords);\n        if (singleValues != null) &#123;\n            return new LeafBucketCollectorBase(sub, ords) &#123;\n                @Override\n                public void collect(int doc, long bucket) throws IOException &#123;\n                    assert bucket == 0;\n                    final int ord = singleValues.getOrd(doc);\n                    if (ord &gt;= 0) &#123;\n                        collectExistingBucket(sub, doc, ord);\n                    &#125;\n                &#125;\n            &#125;;\n        &#125; \n</code></pre>\n<p>我们知道，在 Lucene 里，大部分文件都是不可更新的。一个段一旦生成后就是不可变的，新的数据或者删除数据都需要生成新的段。DocValues 的存储文件也是类似的。所以 DocValues.unwrapSingleton 其实就是做这个判定的，是不是有多个文件 。无论是否则不是都直接创建了一个匿名的 Collector。</p>\n<p>当个文件的很好理解，包含了索引中 newtype 字段所有的值，其下标获取也很自然。</p>\n<pre><code>//singleValues其实就是前面的RandomAccessOrds。\nfinal int ord = singleValues.getOrd(doc); \n</code></pre>\n<p>根据文档号获取值对应的位置，如果 ord &gt;&#x3D;0 则代表有值，否则代表没有值。</p>\n<p>如果有多个文件，则会返回如下的 Collecor:</p>\n<pre><code>else &#123;\n            return new LeafBucketCollectorBase(sub, ords) &#123;\n                @Override\n                public void collect(int doc, long bucket) throws IOException &#123;\n                    assert bucket == 0;\n                    ords.setDocument(doc);\n                    final int numOrds = ords.cardinality();\n                    for (int i = 0; i &lt; numOrds; i++) &#123;\n                        final long globalOrd = ords.ordAt(i);\n                        collectExistingBucket(sub, doc, globalOrd);\n                    &#125;\n                &#125;\n            &#125;; \n</code></pre>\n<p>上面的代码可以保证多个文件最终合起来保持一个文件的序号。什么意思呢？比如 A 文件有一个文档，B 文件有一个，那么最终获取的 globalOrd 就是 0,1 而不会都是 0。此时的 ords 实现类 不是 SingletonSortedSetDocValues 而是</p>\n<pre><code>org.elasticsearch.index.fielddata.ordinals.GlobalOrdinalMapping \n</code></pre>\n<p>对象了。</p>\n<p>计数的方式两个都大体类似。</p>\n<pre><code>docCounts.increment(bucketOrd, 1); \n</code></pre>\n<p>这里的 bucketOrd 其实就是前面的 ord&#x2F;globalOrd。所以整个计算就是填充 docCounts</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>ES 的 Aggregation 机制还是挺复杂的。本文试图通过一个简单的 group by 的例子来完成对其机制的解释。其中 ValueSource 那层我目前也没没完全吃透，如有表述不合适的地方，欢迎大家指出。</p>\n","text":"ElasticSearch-Aggregations-GroupBy-实现源码分析 在前文 ElasticSearch Aggregations 分析 中，我们...","permalink":"/post/MIDDLEWARE/ElasticSearch-Aggregations-GroupBy-实现源码分析","photos":[],"count_time":{"symbolsCount":"13k","symbolsTime":"12 mins."},"categories":[{"name":"newtype","slug":"newtype","count":1,"path":"api/categories/newtype.json"},{"name":"MIDDLEWARE","slug":"newtype/MIDDLEWARE","count":1,"path":"api/categories/newtype/MIDDLEWARE.json"}],"tags":[{"name":"DocValues","slug":"DocValues","count":1,"path":"api/tags/DocValues.json"},{"name":"Aggregator","slug":"Aggregator","count":1,"path":"api/tags/Aggregator.json"},{"name":"Collector","slug":"Collector","count":1,"path":"api/tags/Collector.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#ElasticSearch-Aggregations-GroupBy-%E5%AE%9E%E7%8E%B0%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90\"><span class=\"toc-text\">ElasticSearch-Aggregations-GroupBy-实现源码分析</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C\"><span class=\"toc-text\">准备工作</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5\"><span class=\"toc-text\">查询语句</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Phase-%E6%A6%82%E5%BF%B5\"><span class=\"toc-text\">Phase 概念</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Aggregation-%E7%9A%84%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5\"><span class=\"toc-text\">Aggregation 的相关概念</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Aggregations-%E5%AE%9E%E7%8E%B0%E7%9A%84%E6%9C%BA%E5%88%B6\"><span class=\"toc-text\">Aggregations 实现的机制</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%9F%BA%E4%BA%8E-DocValues-%E5%AE%9E%E7%8E%B0-groupBy-%E6%A6%82%E8%A7%88\"><span class=\"toc-text\">基于 DocValues 实现 groupBy 概览</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#GlobalOrdinalsStringTermsAggregator-x2F-AvgAggregator-%E7%BB%84%E5%90%88%E5%AE%9E%E7%8E%B0\"><span class=\"toc-text\">GlobalOrdinalsStringTermsAggregator&#x2F;AvgAggregator 组合实现</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#BuildAggregation\"><span class=\"toc-text\">BuildAggregation</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%A4%9A%E5%88%86%E7%89%87%E8%81%9A%E5%90%88%E7%BB%93%E6%9E%9C%E5%90%88%E5%B9%B6\"><span class=\"toc-text\">多分片聚合结果合并</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E9%99%84%E5%BD%95\"><span class=\"toc-text\">附录</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%80%BB%E7%BB%93\"><span class=\"toc-text\">总结</span></a></li></ol></li></ol>","author":{"name":"dandeliono","slug":"blog-author","avatar":"https://avatars.githubusercontent.com/u/29496357","link":"/","description":"永远相信美好的事情即将发生","socials":{"github":"https://github.com/dandeliono","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{"title":"在Spring Boot启动时执行代码的几种方法","uid":"61ee30c1a55828f654b62f168fb5fa1d","slug":"JAVA/在Spring Boot启动时执行代码的几种方法","date":"2022-07-11T15:58:46.000Z","updated":"2025-09-30T03:26:25.922Z","comments":true,"path":"api/articles/JAVA/在Spring Boot启动时执行代码的几种方法.json","keywords":"XuGuangSheng","cover":"/covers/spring-boot.jpg","text":"在Spring Boot启动时执行代码的几种方法前言有时候我们需要在应用启动时执行一些代码片段，这些片段可能是仅仅是为了记录 log，也可能是在启动时检查与安装...","permalink":"/post/JAVA/在Spring Boot启动时执行代码的几种方法","photos":[],"count_time":{"symbolsCount":"6.1k","symbolsTime":"6 mins."},"categories":[{"name":"Spring","slug":"Spring","count":4,"path":"api/categories/Spring.json"},{"name":"JAVA","slug":"Spring/JAVA","count":4,"path":"api/categories/Spring/JAVA.json"}],"tags":[{"name":"https","slug":"https","count":44,"path":"api/tags/https.json"},{"name":"小结","slug":"小结","count":1,"path":"api/tags/小结.json"},{"name":"PostConstruct","slug":"PostConstruct","count":1,"path":"api/tags/PostConstruct.json"}],"author":{"name":"dandeliono","slug":"blog-author","avatar":"https://avatars.githubusercontent.com/u/29496357","link":"/","description":"永远相信美好的事情即将发生","socials":{"github":"https://github.com/dandeliono","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"Bulk异常引发的Elasticsearch内存泄漏","uid":"13e3d87bd156131d5858fa5b620de5c7","slug":"MIDDLEWARE/Bulk异常引发的Elasticsearch内存泄漏","date":"2022-07-06T09:41:21.000Z","updated":"2025-09-30T03:26:44.648Z","comments":true,"path":"api/articles/MIDDLEWARE/Bulk异常引发的Elasticsearch内存泄漏.json","keywords":"XuGuangSheng","cover":"/covers/bulkelasticsearch.jpg","text":"Bulk异常引发的Elasticsearch内存泄漏运维线上 ES 集群时，偶然遇到内存泄露的问题，排查问题时看到了这篇文章，清晰明了，所以分享给大家，希望给大...","permalink":"/post/MIDDLEWARE/Bulk异常引发的Elasticsearch内存泄漏","photos":[],"count_time":{"symbolsCount":"6.4k","symbolsTime":"6 mins."},"categories":[{"name":"thread","slug":"thread","count":1,"path":"api/categories/thread.json"},{"name":"MIDDLEWARE","slug":"thread/MIDDLEWARE","count":1,"path":"api/categories/thread/MIDDLEWARE.json"}],"tags":[{"name":"https","slug":"https","count":44,"path":"api/tags/https.json"},{"name":"log","slug":"log","count":4,"path":"api/tags/log.json"},{"name":"bulk","slug":"bulk","count":1,"path":"api/tags/bulk.json"}],"author":{"name":"dandeliono","slug":"blog-author","avatar":"https://avatars.githubusercontent.com/u/29496357","link":"/","description":"永远相信美好的事情即将发生","socials":{"github":"https://github.com/dandeliono","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}