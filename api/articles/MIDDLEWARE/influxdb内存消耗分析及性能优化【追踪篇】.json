{"title":"influxdb内存消耗分析及性能优化【追踪篇】","uid":"6e2f3443cc73a783063825b9fb8c089c","slug":"MIDDLEWARE/influxdb内存消耗分析及性能优化【追踪篇】","date":"2023-04-19T16:40:55.000Z","updated":"2025-09-30T03:26:52.989Z","comments":true,"path":"api/articles/MIDDLEWARE/influxdb内存消耗分析及性能优化【追踪篇】.json","keywords":"XuGuangSheng","cover":"/covers/influxdb.jpg","content":"<h1 id=\"influxdb内存消耗分析及性能优化【追踪篇】\"><a href=\"#influxdb内存消耗分析及性能优化【追踪篇】\" class=\"headerlink\" title=\"influxdb内存消耗分析及性能优化【追踪篇】\"></a>influxdb内存消耗分析及性能优化【追踪篇】</h1><p>由于业务场景需求，在生产环境服务器(32core64G)搭建了基于golang开发的influx时序数据库v1.8版本 ，经过持续一周的运行之后(每天写入约100G数据)，发现服务器内存消耗95%以上，并偶现<strong>SWAP</strong>报警:</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>(swap使用率)[交换内存使用率][79.10744][server_alarm]</p></blockquote>\n<p>使用<strong>top</strong>命令查看当前服务器状态:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">top - 16:06:48 up 31 days,  1:03,  4 users,  load average: 0.01, 0.11, 0.30Tasks:   1 total,   0 running,   1 sleeping,   0 stopped,   0 zombie%Cpu(s): 45.0 us,  3.0 sy,  0.0 ni, 37.9 id, 43.1 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem : 65433636 total,   274968 free, 63048048 used,  2110620 buff/cacheKiB Swap: 32833532 total, 30839420 free,  1994112 used.  1776336 avail Mem   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                       32309 root      20   0  0.411t 0.058t 177080 S   1534 95.3   6926:00 influxd</span><br></pre></td></tr></table></figure>\n\n<p>influx进程物理内存占用58G, 内存使用率95.3%；且当前wa为43.1，说明磁盘IO非常繁忙。于是便思考:</p>\n<ul>\n<li>为什么进程内存消耗那么高？</li>\n<li>为什么磁盘io那么忙？</li>\n</ul>\n<p>(1) 使用influx客户端, 查看influx服务的 <strong>runtime</strong>状态:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; ./influx -host 10.x.xx.xx -port xx -username &#x27;x&#x27; -password &#x27;x&#x27; -execute &quot;show stats&quot;                      name: runtimeAlloc       Frees     HeapAlloc   HeapIdle    HeapInUse   HeapObjects HeapReleased HeapSys     Lookups Mallocs   NumGC NumGoroutine PauseTotalNs   Sys         TotalAlloc-----       -----        ---------       --------      ---------          ----------- ------------ -------                    ------- -------      ----- ------------ ------------                   ---         ----------16389315856 363815829 16389315856 51905806336 16609361920 254434947   44391612416  68515168256 0       618250776 2336  24           15652952340  71222090601 45846325521880 name: databasetags: database=iot_cloudnumMeasurements numSeries--------------- ---------3               20927158</span><br></pre></td></tr></table></figure>\n\n<p>发现当前influxd进程 <strong>HeapIdle</strong>约51G, <strong>HeapInUse</strong>约16G, <strong>HeapReleased</strong>约44G, 当前series数量为2092万左右.随之而来的疑惑:</p>\n<p><strong>为什么进程RES实际占用58G, 而当前进程runtime堆占用内存仅有23G ???</strong></p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>influxdb_v1.8基于go1.13编译，参考runtime相关参数的注释:</p>\n<p>(<a href=\"https://github.com/golang/go/blob/release-branch.go1.13/src/runtime/mstats.go#L245)%EF%BC%8C\">https://github.com/golang/go/blob/release-branch.go1.13/src/runtime/mstats.go#L245)，</a></p>\n<p>按照go的内存分配空间布局规则，可以根据如下计算方式估计go的当前堆内存:</p>\n<p>(HeapIdle)51-(HeapReleased)44+(HeapInUse)16 &#x3D; 23 G</p></blockquote>\n<p>(2) 为了确认是否存在内存泄漏，进一步查看进程的内存块详细数据:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#当前influxd进程id为32309#1.pmap命令查看进程内存块分配&gt; pmap -x 32309 | less32309:   /etc/influxdb/usr/bin/influxd -config /etc/influxdb/influxdb.confAddress           Kbytes     RSS   Dirty Mode  Mapping0000000000400000   14928    2284       0 r-x-- influxd0000000001294000   31092    3664       0 r---- influxd00000000030f1000    4668    4360     368 rw--- influxd0000000003580000     180      96      96 rw---   [ anon ]0000000004ead000     132       0       0 rw---   [ anon ]000000c000000000 66912256 59789960 51476676 rw---   [ anon ] #堆内存00007f80e6469000    4232    1440    1440 rw---   [ anon ]00007f80e6913000 1886000 1872676 1872672 rw---   [ anon ]00007f8159ae5000  232264  230124  230124 rw---   [ anon ]00007f8167dc3000  172360  168804  168804 rw---   [ anon ]00007f817261c000  111564  107452  107452 rw---   [ anon ] #2.查看更详细的每一块内存分配#命令:cat /proc/pid/smaps#如下发现进程堆内存地址空间为:c000000000-cff4000000&gt; cat /proc/32309/smaps | lessc000000000-cff4000000 rw-p 00000000 00:00 0Size:           66912256 kBRss:            59789960 kBPss:            59789960 kBShared_Clean:          0 kBShared_Dirty:          0 kBPrivate_Clean:   8313284 kBPrivate_Dirty:  51476676 kBReferenced:     51368732 kBAnonymous:      59789960 kBAnonHugePages:   5994496 kBSwap:            1055452 kBKernelPageSize:        4 kBMMUPageSize:           4 kBLocked:                0 kBVmFlags: rd wr mr mp me ac sd #3.使用gdb打印堆栈#输入程序地址空间0xc000000000 0xcff4000000&gt; gdb -p 32309&gt;&gt;&gt; dump binary memory ./meminfo.log 0xc000000000 0xcff4000000&gt;&gt;&gt; bt    #查看内存调用栈backtrace&gt;&gt;&gt; q     #退出 #4.查看内存内容meminfo.loghexdump -C ./meminfo.log | less #查看内存块数据</span><br></pre></td></tr></table></figure>\n\n<p>通过内存块调用栈 <strong>bt</strong>命令及导出的 <strong>meminfo.log</strong>文件，并没有发现内存泄漏的导向。</p>\n<p>(3) 使用<strong>go pprof</strong>查看进程累计内存分配 <strong>alloc-space:</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; go tool pprof -alloc_space http://x.x.x.x:xx/debug/pprof/heapFetching profile over HTTP from http://x.x.x.x:xx/debug/pprof/heapSaved profile in /home/yushaolong/pprof/pprof.influxd.alloc_objects.alloc_space.inuse_objects.inuse_space.004.pb.gzFile: influxdType: alloc_spaceTime: Oct 9, 2020 at 3:59pm (CST)Entering interactive mode (type &quot;help&quot; for commands, &quot;o&quot; for options)(pprof) topShowing nodes accounting for 42527GB, 99.59% of 42700.66GB totalDropped 443 nodes (cum &lt;= 213.50GB)      flat  flat%   sum%        cum   cum%   42527GB 99.59% 99.59%    42527GB 99.59%  github.com/influxdata/influxdb/tsdb/index/inmem.(*Index).DropSeriesGlobal /go/src/github.com/influxdata/influxdb/tsdb/index/inmem/inmem.go         0     0% 99.59% 42528.02GB 99.60%  github.com/influxdata/influxdb/services/retention.(*Service).Open.func1 /go/src/github.com/influxdata/influxdb/services/retention/service.go         0     0% 99.59% 42527.94GB 99.60%  github.com/influxdata/influxdb/tsdb.(*Store).DeleteShard.func3 /go/src/github.com/influxdata/influxdb/tsdb/store.go(pprof) list DropSeriesGlobalTotal: 42700.66GBROUTINE ======================== github.com/influxdata/influxdb/tsdb/index/inmem.(*Index).DropSeriesGlobal in /go/src/github.com/influxdata/influxdb/tsdb/index/inmem/inmem.go   42527GB    42527GB (flat, cum) 99.59% of Total         .          .    792:   &#125;         .          .    793:         .          .    794:   i.mu.Lock()         .          .    795:   defer i.mu.Unlock()         .          .    796:   42527GB    42527GB    797:   k := string(key)         .          .    798:   series := i.series[k]         .          .    799:   if series == nil &#123;         .          .    800:           return nil         .          .    801:   &#125;         .          .    802:(pprof)</span><br></pre></td></tr></table></figure>\n\n<p>发现进程在删除series(influx索引)时, 累计消耗了42T的内存空间。说明进程在series删除时消耗了大量的内存堆(<a href=\"https://github.com/influxdata/influxdb/issues/10453)%EF%BC%8C%E6%89%80%E4%BB%A5%E5%8D%A0%E7%94%A8%E5%86%85%E5%AD%98%E4%BC%9A%E5%9C%A8%E6%AD%A4%E6%97%B6%E6%8C%81%E7%BB%AD%E9%A3%99%E9%AB%98%EF%BC%8C%E4%BD%86%E8%BF%99%E4%BA%9B%E5%86%85%E5%AD%98%E5%BA%94%E8%AF%A5%E4%BC%9A%E8%A2%ABGC%E6%8E%89%EF%BC%9F%E9%87%8D%E6%96%B0%E7%9C%8B%E4%B8%80%E4%B8%8Bruntime%E5%8F%8A%E7%B3%BB%E7%BB%9F%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%EF%BC%8C%E5%8F%91%E7%8E%B0%E4%BA%86%E4%B8%80%E4%BA%9B%E7%AB%AF%E5%80%AA\">https://github.com/influxdata/influxdb/issues/10453)，所以占用内存会在此时持续飙高，但这些内存应该会被GC掉？重新看一下runtime及系统内存分配，发现了一些端倪</a>:</p>\n<p>| <strong>进程RES</strong> | <strong>HeapIdle</strong> | <strong>HeapReleased</strong> | <strong>HeapInUse</strong> |<br>| 58G | 51G | 44G | 16G |</p>\n<p>目前influxd进程持有的有效内存为 51-44+16&#x3D;23G, 而系统进程RES为58G。<strong>猜想存在58-23&#x3D;35g的内存，进程标记不再使用，当然系统也没有进行回收。</strong> </p>\n<p>(4) 使用 <strong>memtester</strong> 工具验证猜想:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 内存测试工具 memtester# 使用文档:https://www.cnblogs.com/xiayi/p/9640619.html# 向操作系统申请 30G内存&gt; /usr/local/bin/memtester 30G 1memtester version 4.5.0 (64-bit)Copyright (C) 2001-2020 Charles Cazabon.Licensed under the GNU General Public License version 2 (only). pagesize is 4096pagesizemask is 0xfffffffffffff000want 20480MB (21474836480 bytes)got  20480MB (21474836480 bytes), trying mlock ...locked.Loop 1/1:  Stuck Address       : setting   1</span><br></pre></td></tr></table></figure>\n\n<p>向操作系统申请30G内存后，使用命令查看内存状态:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">top - 16:24:13 up 31 days,  1:21,  5 users,  load average: 1.28, 1.21, 0.70Tasks: 386 total,   2 running, 384 sleeping,   0 stopped,   0 zombie%Cpu(s):  3.1 us,  0.0 sy,  0.0 ni, 96.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem : 65433636 total,   820012 free, 63739976 used,   873648 buff/cacheKiB Swap: 32833532 total, 30837852 free,  1995680 used.  1174164 avail Mem   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND            32309 root      20   0  0.411t   0.029t   8764 S   0.0 48.1   6946:31 influxd14921 root      20   0  30.004g  0.029t    464 R  99.7 48.1   3:25.59 memtester</span><br></pre></td></tr></table></figure>\n\n<p>此时，influxd占用29G内存，memtester占用29G内存。</p>\n<p><strong>果然influxd释放的内存，此时才被系统重新回收</strong>, 翻阅了go的资料，找到了原因</p>\n<p>(<a href=\"https://colobu.com/2019/08/28/go-memory-leak-i-dont-think-so/\">https://colobu.com/2019/08/28/go-memory-leak-i-dont-think-so/</a>):</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>一直以来 go 的 runtime 在释放内存返回到内核时，在 Linux 上使用的是 MADV_DONTNEED，虽然效率比较低，但是会让 RSS（resident set size 常驻内存集）数量下降得很快。不过在 go 1.12 里专门针对这个做了优化，runtime 在释放内存时，使用了更加高效的 MADV_FREE 而不是之前的 MADV_DONTNEED。这样带来的好处是，一次 GC 后的内存分配延迟得以改善，runtime 也会更加积极地将释放的内存归还给操作系统，以应对大块内存分配无法重用已存在的堆空间的问题。不过也会带来一个副作用：RSS 不会立刻下降，而是要等到系统有内存压力了，才会延迟下降。为了避免像这样一些靠判断 RSS 大小的自动化测试因此出问题，也提供了一个 GODEBUG&#x3D;madvdontneed&#x3D;1 参数可以强制 runtime 继续使用 MADV_DONTNEED。</p></blockquote>\n<p>原来是由于go内部优化而使进程内存没有立即释放，至此解答了内存高消耗的疑惑。</p>\n<p>使用 <strong>iostat</strong> 命令查看磁盘io状态:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#系统命令iostat&gt; iostat -x 1 3 #每秒打印1次，打印3次磁盘状态#示例第二次状态avg-cpu:  %user   %nice %system %iowait  %steal   %idle           7.98    0.00    3.80   10.33    0.00   77.89 Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %utilsda              26.00  1480.00 2544.00 1692.00 28800.00 33576.00    29.45     4.18    0.98    1.59    0.06   0.23  98.70dm-0              0.00     0.00  316.00    0.00  1384.00     0.00     8.76     0.42    1.36    1.36    0.00   0.88  27.90dm-4              0.00     0.00 2198.00 3163.00 27192.00 33576.00    22.67     3.48    0.64    1.48    0.06   0.18  97.50</span><br></pre></td></tr></table></figure>\n\n<p>按照 linux进程io磁盘性能分析 ,得知influxd进程写盘的Device为<strong>dm-4</strong> ，指标分析如下:</p>\n<ul>\n<li>当前磁盘iops为5361&#x2F;s (r + w)</li>\n<li>每秒io读取约27M&#x2F;s, 写入约33M&#x2F;s</li>\n<li>io队列中，有3.48个堆积 (avgqu-sz)</li>\n<li>每次io等待 0.47ms (await), 处理耗时0.17ms (svctm)</li>\n<li>%util为97.5%，接近100%，说明I&#x2F;O请求太多，I&#x2F;O系统已经满负荷</li>\n</ul>\n<p>发现influx进程对磁盘的io消耗过大。</p>\n<p>通过以上分析，可以得到:</p>\n<ul>\n<li>influx使用 <strong>inmem</strong> 引擎时(默认)，在retention policy时会消耗过高的内存</li>\n<li>使用 <strong>GODEBUG&#x3D;madvdontneed&#x3D;1</strong> 可以让go程序尽快释放内存</li>\n<li>influx磁盘的iops过高，应该从(增大内存buffer&#x2F;增加批量写落盘)方面进行优化</li>\n</ul>\n<p>因此对配置文件influxdb.conf做了如下优化:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 详细配置说明见官方文档# https://docs.influxdata.com/influxdb/v1.8/administration/config/#data-settings [data]  #说明: wal预写日志log,用于事务一致性  #默认为0，每次写入都落盘。  #修改为1s, 根据业务场景，不保证强一致性,可采用异步刷盘  #[优化点]:用于减轻磁盘io压力  wal-fsync-delay = &quot;1s&quot;     #说明: influx索引  #默认为inmem,创建内存型索引,在delete retention会消耗过高内存  #修改为tsi1, 注意重建tsi1索引(https://blog.csdn.net/wzy_168/article/details/107043840)  #[优化点]:降低删除保留策略时的内存消耗  index-version = &quot;tsi1&quot;     #说明: 压缩TSM数据,一次落盘的吞吐量  #默认48m  #修改为64m  #[优化点]:增大写入量，减轻io压力  compact-throughput = &quot;64m&quot;</span><br></pre></td></tr></table></figure>\n\n<p>修改配置之后，执行如下命令启动influx进程:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">env GODEBUG=madvdontneed=1 /usr/bin/influxd  -config  /usr/bin/influxdb.conf</span><br></pre></td></tr></table></figure>\n\n<p>influxd进程重新运行一周之后，再次观察系统状态:</p>\n<p>(1) 内存消耗约占55%左右:</p>\n<p><img src=\"https://zyun.360.cn/blog/wp-content/uploads/2021/03/tupian-1024x557.png\"></p>\n<p>(2) 磁盘iops约为200左右，util占用6.2%。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">avg-cpu:  %user   %nice %system %iowait  %steal   %idle          7.21    0.00    1.00   0.16    0.00   91.64 Device:         rrqm/s   wrqm/s     r/s     w/s       rkB/s    wkB/s      avgrq-sz   avgqu-sz   await   r_await   w_await  svctm   %utilsda                  0.00    39.00       5.00  161.00    20.00   28036.00   338.02     0.25           1.51     10.40      1.24         0.37    6.10dm-4              0.00     0.00         5.00  189.00    20.00   28036.00   289.24     0.26           1.32     10.60      1.07         0.32    6.20</span><br></pre></td></tr></table></figure>\n\n<p>发现进程运行符合预期,问题得到初步解决。</p>\n<ul>\n<li><strong>服务器体系(SMP, NUMA, MPP)与共享存储器架构(UMA和NUMA):</strong> <a href=\"https://cloud.tencent.com/developer/article/1372348\">https://cloud.tencent.com/developer/article/1372348</a></li>\n<li><strong>理解virt res shr之间的关系:</strong> <a href=\"https://www.orchome.com/298\">https://www.orchome.com/298</a></li>\n<li><strong>SWAP的罪与罚:</strong> <a href=\"https://blog.huoding.com/2012/11/08/198\">https://blog.huoding.com/2012/11/08/198</a></li>\n<li><strong>go调度器:</strong> <a href=\"https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-goroutine/\">https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-goroutine/</a></li>\n<li><strong>NUMA-aware scheduler for Go:</strong> <a href=\"https://docs.google.com/document/u/0/d/1d3iI2QWURgDIsSR6G2275vMeQ_X7w-qxM2Vp7iGwwuM/pub\">https://docs.google.com/document/u/0/d/1d3iI2QWURgDIsSR6G2275vMeQ_X7w-qxM2Vp7iGwwuM/pub</a></li>\n</ul>\n","text":"influxdb内存消耗分析及性能优化【追踪篇】由于业务场景需求，在生产环境服务器(32core64G)搭建了基于golang开发的influx时序数据库v1....","permalink":"/post/MIDDLEWARE/influxdb内存消耗分析及性能优化【追踪篇】","photos":[],"count_time":{"symbolsCount":"11k","symbolsTime":"10 mins."},"categories":[{"name":"runtime","slug":"runtime","count":1,"path":"api/categories/runtime.json"},{"name":"MIDDLEWARE","slug":"runtime/MIDDLEWARE","count":1,"path":"api/categories/runtime/MIDDLEWARE.json"}],"tags":[{"name":"https","slug":"https","count":44,"path":"api/tags/https.json"},{"name":"使用","slug":"使用","count":5,"path":"api/tags/使用.json"},{"name":"influx","slug":"influx","count":1,"path":"api/tags/influx.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#influxdb%E5%86%85%E5%AD%98%E6%B6%88%E8%80%97%E5%88%86%E6%9E%90%E5%8F%8A%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E3%80%90%E8%BF%BD%E8%B8%AA%E7%AF%87%E3%80%91\"><span class=\"toc-text\">influxdb内存消耗分析及性能优化【追踪篇】</span></a></li></ol>","author":{"name":"dandeliono","slug":"blog-author","avatar":"https://avatars.githubusercontent.com/u/29496357","link":"/","description":"永远相信美好的事情即将发生","socials":{"github":"https://github.com/dandeliono","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{"title":"influxdb内存消耗分析及性能优化—2","uid":"9af4a9fff87dbbddf6cd710f2420d952","slug":"MIDDLEWARE/influxdb内存消耗分析及性能优化—2","date":"2023-04-19T16:40:55.000Z","updated":"2025-09-30T03:26:52.937Z","comments":true,"path":"api/articles/MIDDLEWARE/influxdb内存消耗分析及性能优化—2.json","keywords":"XuGuangSheng","cover":"/covers/influxdb2.jpg","text":"influxdb内存消耗分析及性能优化—2 由于业务场景需求，在生产环境服务器(32core64G)搭建了基于golang开发的influx时序数据库v1.8版...","permalink":"/post/MIDDLEWARE/influxdb内存消耗分析及性能优化—2","photos":[],"count_time":{"symbolsCount":"10k","symbolsTime":"9 mins."},"categories":[{"name":"influx","slug":"influx","count":1,"path":"api/categories/influx.json"},{"name":"MIDDLEWARE","slug":"influx/MIDDLEWARE","count":1,"path":"api/categories/influx/MIDDLEWARE.json"}],"tags":[{"name":"使用","slug":"使用","count":5,"path":"api/tags/使用.json"},{"name":"influxd","slug":"influxd","count":2,"path":"api/tags/influxd.json"},{"name":"runtime","slug":"runtime","count":1,"path":"api/tags/runtime.json"}],"author":{"name":"dandeliono","slug":"blog-author","avatar":"https://avatars.githubusercontent.com/u/29496357","link":"/","description":"永远相信美好的事情即将发生","socials":{"github":"https://github.com/dandeliono","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"influxdb内存消耗分析及性能优化","uid":"9736c920c0447b484184935c1c343c5b","slug":"MIDDLEWARE/influxdb内存消耗分析及性能优化","date":"2023-04-19T16:34:36.000Z","updated":"2025-09-30T03:26:51.772Z","comments":true,"path":"api/articles/MIDDLEWARE/influxdb内存消耗分析及性能优化.json","keywords":"XuGuangSheng","cover":"/covers/influxdb.jpg","text":"influxdb内存消耗分析及性能优化 influxdb目前支持内存型索引inmem及文件型索引tsi1。之前追踪篇将influxd索引修改为tsi1之后，经过...","permalink":"/post/MIDDLEWARE/influxdb内存消耗分析及性能优化","photos":[],"count_time":{"symbolsCount":"10k","symbolsTime":"9 mins."},"categories":[{"name":"influxdb","slug":"influxdb","count":1,"path":"api/categories/influxdb.json"},{"name":"MIDDLEWARE","slug":"influxdb/MIDDLEWARE","count":1,"path":"api/categories/influxdb/MIDDLEWARE.json"}],"tags":[{"name":"CPU","slug":"CPU","count":3,"path":"api/tags/CPU.json"},{"name":"SHR","slug":"SHR","count":1,"path":"api/tags/SHR.json"},{"name":"influxd","slug":"influxd","count":2,"path":"api/tags/influxd.json"}],"author":{"name":"dandeliono","slug":"blog-author","avatar":"https://avatars.githubusercontent.com/u/29496357","link":"/","description":"永远相信美好的事情即将发生","socials":{"github":"https://github.com/dandeliono","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}